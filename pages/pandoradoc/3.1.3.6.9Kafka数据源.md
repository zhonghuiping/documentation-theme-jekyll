Kafka reader 输出的是内容可根据具体情况自定义 parser 进行解析。

目前我们提供了两个Kafka Reader，您需要根据您的kafka实际版本进行选择。

新版与老版在基础配置的主要区别是老版填的是zookeeper地址，而新版填的是kafka地址；在高级选项里新版加入了鉴权机制，使用场景覆盖的更加广泛。

## **一、 新版Kafka(newkafak)数据源，针对0.9及以后版本的Kafka **



### **基础配置**

![](https://odum9helk.qnssl.com/FlyCY2XI_bb_mdmAoR4O7OS2itRa)

* consumer 组名称(`kafka_groupid`）：kafka `组名`，多个 logkit 同时消费时写同一个组名可以协同读取数据。
  
* topic 名称(`kafka_topic`)：kafka 的 `topic` 名称列表。
  
* broker 地址(`kafka_brokers`)：kafka brokers 地址列表，多个用`逗号`分隔，常用端口是 `9092`。

* 读取起始位置(`read_from`): `oldest`：从 partition 最开始的位置，`newest`：从 partition 最新的位置。默认从 oldest 位置开始消费。


### **高级选项**

![](https://odum9helk.qnssl.com/FqpyMautQF7_OHKvZidxc_TLoYKi)

* 来源标签(`datasource_tag`): 把读取kafka topic 也作为标签，记录到解析出来的数据结果中，此处填写标签名称

* 客户端标识(`client_id`) :消费kafka时显示的客户端标识，默认为`logkit`

* SASL用户名(`sasl_username`): 使用SASL协议进行鉴权的用户名

* SASL用户名(`sasl_password`): 使用SASL协议进行鉴权的密码

* SSL/TLS证书授权文件路径(`tls_ca`): SSL/TLS证书授权路径

* SSL/TLS证书文件路径(公钥)(`tls_cert`): SSL/TLS证书路径(公钥)

* SSL/TLS私钥路径(`tls_key`):  SSL/TLS证书路径(私钥)

* 使用TLS但忽略认证(`insecure_skip_verify`): 对于https的访问忽略认证检查



## 二、老版Kafka(kafka)数据源，针对0.8及以前版本的Kafka



### **基础配置信息**


![](https://odum9helk.qnssl.com/Fl8qLr6sF6yd_4l8_mWZCIlp2vgY)

  * consumer 组名称(`kafka_groupid`）：kafka `组名`，多个 logkit 同时消费时写同一个组名可以协同读取数据。
  
  * topic 名称(`kafka_topic`)：kafka 的 `topic` 名称列表。
  
  * zookeeper 地址(`kafka_zookeeper`)：zookeeper 地址列表，多个用`逗号`分隔，常用端口是 `2181`。

  * 读取起始位置(`read_from`): `oldest`：从 partition 最开始的位置，`newest`：从 partition 最新的位置。默认从 oldest 位置开始消费。
 
 
### **高级选项**
  
	
![](https://odum9helk.qnssl.com/FjVxOEBZLwgWDUEIRQcDwZdm4fBT)
	
  * zookeeper 中 kafka 根路径(`kafka_zookeeper_chroot`)：kafka 在 zookeeper 根路径中的地址。
  * zookeeper超时时间 (`kafka_zookeeper_timeout`): 从 zookeeper 读取数据的超时时间，默认1s。

