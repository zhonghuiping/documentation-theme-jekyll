logkit  Pro是一款专业的日志采集工具,可以将不同数据源如：关系型数据库（MySQL等）、非关系型数据库（MongoDB）、文件（csv等）、消息队列（kafka）、网络数据（TCP、Http POST）等的数据便捷地发送到各种数据平台（ 智能日志管理平台平台、ElasticSearch、InfluxDB、Kafka等）进行数据存储、分析，整个发送流程在 logkit Pro 页面上得到可视化。

logkit Pro 支持各种数据格式的日志一键解析，直接将原始日志转化为结构化数据。并且支持更精细的字段转换，如将 ip 字符串扩展为 ip 对应的区域、城市、省份、运营商等信息，或者将指定字段解析为时间等。可以满足您的各种数据解析需求。

logkit Pro 采集日志并发送到智能日志管理平台的工作流程如下：

![](https://pandora-kibana.qiniu.com/quickstart/step.png)

# **logkit Pro 支持的采集数据源**

* File: 读取文件中的日志数据，包括 csv 格式的文件，kafka-rest 日志文件， nginx 日志文件等，并支持多种读取模式（fileauto、dir、file、tailx）
* MySQL: 读取 MySQL 中的数据。
* MSSQL: 读取 Microsoft SQL Server中的数据。
* Postgre SQL: 读取 PostgreSQL 中的数据。
* ElasticSearch: 读取 ElasticSearch 中的数据。
* MongoDB: 读取 MongoDB 中的数据。
* Kafka: 读取 Kafka 中的数据。
* Redis: 读取 Redis 中的数据。 
* Socket: 读取 tcp\udp\unixsocket 协议中的数据。
* Http: 作为 http 服务端，接受 POST 请求发送过来的数据。
* Script: 支持执行脚本，读取执行结果中的数据。
* Snmp: 主动抓取 Snmp 服务中的数据。
* AWS CloudWatch: 主动抓取 AWS CloudWatch接口中的数据。
* AWS S3: 主动抓取 AWS S3中的数据。

[点此](/insight/manual/4750/logkit-pro-readers)获取更详细的数据源介绍。


# **logkit Pro 支持的发送服务端**

* Pandora Sender: 发送到智能日志管理平台。
* File Sender: 发送到本地文件。
* MongoDB Accumulate Sender: 聚合后发送到 MongoDB 服务。
* InfluxDB Sender: 发送到 InfluxDB 服务。
* 消费数据但不发送：不执行发送行为。
* Elasticsearch Sender: 发送到 ElasticSearch 服务。
* Kafka Sender: 发送到 Kafka 服务。
* Http Sender: 以 Http POST 请求的方式发送数据。

[点此](/insight/manual/4782/senders)获取更详细的发送端介绍。


# 数据解析与变换功能

* 数据解析：在数据被 logkit Pro 读取后，用户可以根据需要配置日志解析格式，抽取数据中的字段，转化为结构化数据。logkit Pro 支持包括 json、csv、grok等大多数主流日志解析方式。

  [点此](/insight/manual/4755/parsers)了解更多 logkit Pro 数据解析功能。
  
* 字段转换: 针对字段做数据变换, 来满足整体数据解析满足不了的需求，比如将 ip 字符串扩展为 ip 对应的区域、城市、省份、运营商等信息。支持包括字符串替换、ip 扩展、格式转换等多种数据变换方式。

  [点此](/insight/manual/4767/transformers)了解更多 logkit Pro 数据字段变换功能。



