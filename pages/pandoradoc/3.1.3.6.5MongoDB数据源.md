MongoDB reader 输出的是 json 字符串，需要使用 json parser 解析。

### **基础配置信息**

  * 数据库地址(mongo_host)：mongodb 的 url 地址，基础写法为填写 mongo 的 host 地址以及端口，默认是 localhost:9200，扩展形式可以写为：mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]，用户名密码也可以写在这里。
  
  * 递增的主键(mongo_offset_key)：选填，指定一个 mongo 的列名，作为 offset 的记录，类型必须是整型(比如 unixnano 的时间，或者自增的 primary key)。 每次查询会指定这个 key 做 where 条件大于上次查询最后的记录这样的限制，避免单次查询性能消耗过大，同时也支持持续的数据导入过程中避免数据重复。 若不指定，则使用 mongo 的_id 键，_id 键是由时间戳(秒)+机器+进程号+自增位组成的，在低频数据写入的情况下是自增的，在多机器组成的 mongo 集群高并发写入的情况下，_id 不是自增的，存在漏数据的可能。 默认使用 _id，也保证了在纯粹从静态的 mongo 数据库导入 Pandora 过程中，若重启 logkit Pro 不会导致数据重复。

### **高级选项**

  * 数据保存路径(meta_path): 默认自动生成，是 reader 的读取 offset 的记录路径，记录 mongo 读取时的 Offset，路径必须是一个文件夹。
  
  * 分批查询的单批次大小(mongo_limit_batch): 默认为 "100", 表示单次请求获取的数据量。
  
  * 定时任务(mongo_cron): 默认没有定时任务。定时任务触发周期，支持三种写法。
    * 直接写 "loop",任务会不停的循环，执行完一次再接着执行下一次，后面可以跟循环的间歇时间，如 "loop 10s"，表示每次循环间隔 10s，支持的单位还有"m（分钟）"，"h(小时)"
    * crontab 的写法,类似于`* * * * * *` ，对应的是秒(0~59)，分(0~59)，时(0~23)，日(1~31)，月(1-12)，星期(0~6)，填*号表示所有遍历都执行。
    * 描述式写法,类似于 "@midnight", "@every 1h30m"，必须`@`符合开头，目前支持`@hourly`,`@weekly`,`@monthly`,`@yearly`,`@every <time duration>`
  
    
* 数据过滤方式(mongo_filters):表示 collection 的过滤规则，默认不过滤，全部获取。最外层是 collection 名称，里面对应的是 json 的规则。如示例所示，表示 foo 这个 collection，i 字段的值大于 10 的全部数据。

!>注意:导出 mongo 的字段中，包含`_id`的话，在打入 Pandora 的数据中，默认也会包含`_id`，这份数据如果再要导出到 LogDB，就会出现错误，因为_id 是 LogDB 的保留字段。此时可以在 Pandora Sender 中指定 pandora_schema 字段设置别名，如 `"pandora_schema":"_id id,..."`, 这样就可以正常导入。其他出现字段冲突的情况都可以使用别名功能处理。